{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artctoc data\n",
    "\n",
    "Cleaning GPS and analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Faire la jointure entre les données individus et les positions GPS\n",
    "\n",
    "le pb est que les données attributaires des oiseaux ont une GLS ID qui ne correspond pas directement aux identifiants du fichier GPS (id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Bird_ID', 'GLS_ID', 'Sex', 'Date', 'Nest', 'Nest_content',\n",
       "       'Capture_method', 'Headbill', 'Culmen', 'Wing', 'Right_tarsus', 'Mass',\n",
       "       'Index_body_condition', 'Muscle_Pectoral', 'Score_Personal', 'Long_Egg',\n",
       "       'Long_Egg_cm', 'Larg_Egg', 'Larg_Egg_cm', 'Vol_egg', 'Arrival_date',\n",
       "       'Arrival_date_num', 'Arrival_date_propre', 'Arrival_date_propre_num',\n",
       "       'date_enter_nest', 'date_enter_nest_num', 'Hatch_date',\n",
       "       'Hatch_date_num', 'weigh_hatching', 'Hatching_success',\n",
       "       'Chick_mass_gain_(g/d)_1st_15d', 'pente_chick_growth_1-15d',\n",
       "       'N_SIA_Blood', 'N_SIA_head_Feather', 'C_SIA_Blood',\n",
       "       'C_SIA_head_Feather', 'Chick_sex', 'Cortico', 'Hg_HF', 'Hg_blood',\n",
       "       'Season_Hg_Blood', 'Hg_BF', 'BF_side', 'Long_Median_15Oct_20Fev',\n",
       "       'Lat_Median_15Oct_20Fev', 'Long_Median_DecJan', 'Lat_Median_DecJan',\n",
       "       'Long_Median_Dec_20Fev', 'Lat_Median_Dec_20Fev', 'd_PL_15Oct_20Fev',\n",
       "       'd_PL_DecJan', 'd_PL_1Dec_20Fev', 'Max_d_col__Dec_Jan',\n",
       "       'Max_d_col__15Oct_20Fev', 'PL_Lat', 'PL_Long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"C:\\Travail\\Enseignement\\Cours_M2_python\\Projet_Arctox\\data for analyses_2010_2011_analyses.xls\", \n",
    "                            sheet_name=\"data for analyses_2010_2011_ana\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GLS_ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gps['id'].unique())\n",
    "print(gps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Lire le fichier complet des positions GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_gps = pd.read_csv(\"C:\\Travail\\Enseignement\\Cours_M2_python\\\\2023\\data\\kap_hoegh_gls_complet.csv\", sep=\";\", encoding='utf-8')\n",
    "print(df_gps.shape)\n",
    "gps = gpd.GeoDataFrame(\n",
    "    df_gps, geometry=gpd.points_from_xy(df_gps.long, df_gps.lat), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "\n",
    "print(gps.columns)\n",
    "print(gps.shape)\n",
    "print(gps.id.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer les positions GPS des oiseaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le nettoyage, nous allons nous inspirer d'une approche par lissage temporel, pour supprimer les latitudes anormales\n",
    "- voir le package https://pypi.org/project/tsmoothie/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/20618804/how-to-smooth-a-curve-in-the-right-way\n",
    "\n",
    "x = np.linspace(0,2*np.pi,100) #timestampgps\n",
    "y = np.sin(x) + np.random.random(100) * 0.2 #lat\n",
    "\n",
    "# operate smoothing\n",
    "import tsmoothie \n",
    "from tsmoothie.smoother import ConvolutionSmoother\n",
    "\n",
    "smoother = ConvolutionSmoother(window_len=5, window_type='ones')\n",
    "smoother.smooth(y)\n",
    "\n",
    "# generate intervals\n",
    "low, up = smoother.get_intervals('sigma_interval', n_sigma=2)\n",
    "\n",
    "### End of adaptation\n",
    "\n",
    "# plot the smoothed timeseries with intervals\n",
    "# Avec BOKEH \n",
    "from bokeh.plotting import show, figure, output_file, output_notebook\n",
    "\n",
    "#output_notebook() \n",
    "output_file(\"smoothed_data_example.html\")\n",
    "\n",
    "p = figure(width=800, height=400)\n",
    "\n",
    "# add a line renderer for smoothed line\n",
    "p.line(x, smoother.smooth_data[0], line_width =3, color='red')\n",
    "p.circle(x, smoother.data[0], size =3, fill_color=\"white\")\n",
    "# add an area between low and up smoothed data\n",
    "p.varea(x=x,y1=low[0], y2=up[0], alpha=0.3)\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. vous avez besoin d'un axe temporel : une colonne timestamp\n",
    "\n",
    "- https://realpython.com/python-datetime/ \n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    "- https://www.delftstack.com/fr/howto/python-pandas/how-to-convert-dataframe-column-to-datetime-in-pandas/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Timestamp.combine(gps.date, gps.time)\n",
    "#print(gps.date+' '+gps.time)\n",
    "gps['timestamp'] = gps.date+' '+gps.time\n",
    "format_string = \"%Y-%m-%d %H:%M:%S\"\n",
    "from datetime import datetime\n",
    "\n",
    "gps.timestamp = gps.timestamp.apply(lambda x: datetime.strptime(x, format_string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Mettre en oeuvre un lissage sur les latitudes\n",
    "Adapt the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From now, adapt the code for smoothing bad latitudes\n",
    "## https://stackoverflow.com/questions/20618804/how-to-smooth-a-curve-in-the-right-way\n",
    "\n",
    "x = gps.timestamp.values #timestampgps\n",
    "y = gps.clean_lat.values #df.loc[:,['clean_lat']].values\n",
    "\n",
    "# operate smoothing\n",
    "import tsmoothie \n",
    "from tsmoothie.smoother import ConvolutionSmoother\n",
    "\n",
    "#First simplest one : moving average of span = 5\n",
    "#smoother = ConvolutionSmoother(window_len=5, window_type='ones')\n",
    "#smoother.smooth(y)\n",
    "\n",
    "#https://pypi.org/project/tsmoothie/\n",
    "#https://fr.wikipedia.org/wiki/Fen%C3%AAtrage \n",
    "#Second one : moving weighted average of span = 10, using hamming function\n",
    "smoother = ConvolutionSmoother(window_len=20, window_type='hamming')\n",
    "smoother.smooth(y)\n",
    "\n",
    "# generate intervals\n",
    "low, up = smoother.get_intervals('sigma_interval', n_sigma=2)\n",
    "\n",
    "### End of adaptation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the smoothed timeseries with intervals\n",
    "from bokeh.plotting import show, figure, output_file, output_notebook\n",
    "\n",
    "#output_notebook() \n",
    "output_file(\"smoothed_data.html\")\n",
    "\n",
    "p = figure(width=1600, height=800, x_axis_type='datetime')\n",
    "\n",
    "# add a line renderer for smoothed line\n",
    "p.line(x, smoother.smooth_data[0], line_width =3, color='blue')\n",
    "p.circle(x, smoother.data[0], size =3, fill_color=\"white\")\n",
    "# add an area between low and up smoothed data\n",
    "p.varea(x=x,y1=low[0], y2=up[0], alpha=0.3)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the result\n",
    "#df['smooth_lat'] = smoother.smooth_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joindre GPS et données d'analyse\n",
    "\n",
    "- A gauche, les positions GPS\n",
    "- A droite, les données attributaires\n",
    "\n",
    "Pb : il faut un peu nettoyer df.GLS_ID.unique() en supprimant\n",
    "- MK12-12A\n",
    "- MK18-\n",
    "- MK14-\n",
    "- SO-\n",
    "du fichier d'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(type(df.GLS_ID.values))\n",
    "# Caster en str ce mélange de numerique et de chaînes de caractères\n",
    "df.GLS_ID = df.GLS_ID.apply(lambda _: str(_))\n",
    "print(type(df.GLS_ID.values))\n",
    "\n",
    "clean_GLSID = []\n",
    "for i, r in df.iterrows():\n",
    "    clean_gls_id = r.GLS_ID.upper().replace('MK12-12A', '').replace('MK14-', '').replace('MK18-', '').replace('SO-', '')\n",
    "    clean_GLSID = np.append(clean_GLSID, clean_gls_id)\n",
    "\n",
    "print(pd.unique(clean_GLSID))\n",
    "df['clean_GLSID'] = clean_GLSID\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On fait la jointure sur des type identiques (id passe de int à string)\n",
    "gps.id = gps.id.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Supprimer les valeurs NAN du fichier d'Analyses\n",
    "\n",
    "#df.dropna(subset=['clean_GLSID'], inplace = True)\n",
    "df  = df[df.clean_GLSID != 'NAN']\n",
    "print(df.shape)\n",
    "df.clean_GLSID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.clean_GLSID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jointure\n",
    "\n",
    "data = gps.join(df.set_index('clean_GLSID'), on='id', lsuffix='_gps', rsuffix='_ana')\n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poursuivre l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Index_body_condition.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
