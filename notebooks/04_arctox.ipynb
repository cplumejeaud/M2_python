{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arctox code\n",
    "\n",
    "@author: Christine Plumejeaud-Perreau, UMR 7301 Migrinter,\n",
    "- Master M2 SPE, UE '270-3-71 - Geospatial and web development' \n",
    "- Created on 15 november 2023\n",
    "- Updated on 15/11/2023\n",
    "\n",
    "# Work to was proposed as TEA\n",
    "\n",
    "- Import GPS values from the CSV file ‘Kap Hoegh GLS 20102011_sun3.csv’ (there are outliers, because of the false latitudes)\n",
    "- Build the bird path : make a GROUP BY bird_id, and sort in chronological order each point per bird \n",
    "- Compute the total length of the path\n",
    "- Connect through a python program to database\n",
    "- Plot a bokeh map and/or a folium map (you can use geopandas)\n",
    "- Remove/clean abnormal values : outliers detection\n",
    "\n",
    "- replace the bad latitude values with clever values using python / SQL : outliers detection\n",
    "- redo the job of computing points and paths of birds using python / SQL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GPS values from the CSV file ‘Kap Hoegh GLS 20102011_sun3.csv’ (there are outliers, because of the false latitudes)\n",
    "\n",
    "The destination is the savoie database, inside your schema. \n",
    "For the example, I take my own schema arctic_christine in the savoie database on the serveur\n",
    "\n",
    "To show how a SSH tunnel can be done, I stop Dbeaver. \n",
    "Read the doc : https://sshtunnel.readthedocs.io/en/latest/ \n",
    "\n",
    "Equivalent to 'ssh -N -L 8005:localhost:5432 -v tpm2@134.158.33.178'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's open a SSH connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's open a SSH connection\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "# https://sshtunnel.readthedocs.io/en/latest/\n",
    "\n",
    "remote_server_ip = '134.158.33.178'\n",
    "remote_server_port = 22\n",
    "remote_server_username = 'tpm2'\n",
    "remote_server_ssh_password=\"geoMigr2022\" #Hide this before commit\n",
    "#remote_bind_address=(PRIVATE_SERVER_IP, 22),\n",
    "db_server_ip = '127.0.0.1'\n",
    "db_server_port = 8009\n",
    "private_server_ip = '127.0.0.1'\n",
    "private_server_port = 5432\n",
    "\n",
    "server = SSHTunnelForwarder(\n",
    "    (remote_server_ip, 22),\n",
    "    ssh_username=remote_server_username,\n",
    "    ssh_password=remote_server_ssh_password,\n",
    "    remote_bind_address=(private_server_ip, private_server_port),\n",
    "    local_bind_address=(db_server_ip, db_server_port) )\n",
    "try:\n",
    "    server.start()\n",
    "except:\n",
    "    print(\"trouble connecting to the tunnel. We will assume it is already up\")\n",
    "else:\n",
    "    print(\"server is started and on port \",server.local_bind_port)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the connection with SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the connection with SQLAlchemy\n",
    "\n",
    "import pandas.io.sql as sql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://christine:christineM2@localhost:8009/savoie')\n",
    "ORM_conn=engine.connect()\n",
    "ORM_conn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the CSV file into the arctic_christine schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CSV file into the arctic_christine schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Travail/Enseignement/Cours_M2_python/2023/data/Kap Hoegh GLS 20102011_sun3_saison.csv', sep=';', encoding='utf-8')\n",
    "print(df)\n",
    "\n",
    "# A few cleaning before saving the data\n",
    "\n",
    "#1. rename some columns\n",
    "df = df.rename(columns={\"date\": \"dategps\", \"time\": \"timegps\", \"Long\" : \"long\", \"Lat_compensate\" : \"lat_compensate\"})\n",
    "\n",
    "#2. remove useless columns\n",
    "df = df.drop(['ID_ID', 'Lat1'], axis=1)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. save it with pandas into the database\n",
    "df.to_sql('kap_hoegh_gls', ORM_conn,  schema='arctic_christine', if_exists='replace' ) \n",
    "ORM_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking into DBeaver\n",
    "\n",
    "Look at the table definition. Is there a problem ?\n",
    "```SQL\n",
    "CREATE TABLE arctic_christine.kap_hoegh_gls (\n",
    "\t\"index\" int8 NULL,\n",
    "\t\"ID\" int8 NULL,\n",
    "\tsex text NULL,\n",
    "\t\"Period\" text NULL,\n",
    "\tdategps text NULL,\n",
    "\tweek int8 NULL,\n",
    "\ttimegps text NULL,\n",
    "\tlat_compensate float8 NULL,\n",
    "\tlong float8 NULL\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's clean the data with some few SQL\n",
    "\n",
    "The SQL to do \n",
    "\n",
    "```SQL\n",
    "alter table kap_hoegh_gls drop column \"index\";\n",
    "\n",
    "alter table kap_hoegh_gls rename column \"ID\" to ID;\n",
    "\n",
    "alter table kap_hoegh_gls alter column dategps type date USING dategps::date;\n",
    "\n",
    "alter table kap_hoegh_gls alter column timegps type time USING timegps::time;\n",
    "\n",
    "-- select  (dategps ||' '|| timegps)::timestamp from kap_hoegh_gls;\n",
    "\n",
    "alter table kap_hoegh_gls add column timestampgps timestamp ;\n",
    "update kap_hoegh_gls set timestampgps =  (dategps ||' '|| timegps)::timestamp;\n",
    "\n",
    "select st_makepoint(long::float, lat_compensate::float) from kap_hoegh_gls\n",
    "```\n",
    "\n",
    "We use psycog2 connection (for the example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using psycog2 \n",
    "(you control better the connection parameters with postgres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using psycog2 connection (for the example)\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "def getConnection() : \n",
    "    host = 'localhost'\n",
    "    port = '8009'\n",
    "    user = 'christine'\n",
    "    password = 'christineM2'\n",
    "    dbname='savoie'\n",
    "\n",
    "    options=\"'-c search_path=arctic_christine,public'\" #The schema you want to modify, arctic_christine first, then public\n",
    "\n",
    "    connectString = 'host=' + host + ' port=' + port + ' user=' + user + ' dbname=' + dbname + ' password=' + password + ' options=' + options\n",
    "    #connectString = 'host=' + host + ' port=' + port + ' user=' + user + ' dbname=' + dbname + ' password=' + password \n",
    "    print(connectString)\n",
    "    #host=localhost port=8005 user=christine dbname=savoie password=christineM2 options='-c search_path=arctic_christine,public'\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(connectString)\n",
    "    except Exception as e:\n",
    "        print(\"I am unable to connect to the database. \" + str(e))\n",
    "    # Test DB\n",
    "    if conn is not None:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute('select count(*) from pg_namespace')\n",
    "        result = cur.fetchone()\n",
    "        if result is None:\n",
    "            print('open_connection Failed to get count / use of database failed')\n",
    "        else:\n",
    "            print('open_connection Got database connexion : ' + str(result[0]))\n",
    "    else:\n",
    "        print('open_connection Failed to get database connexion')\n",
    "    return conn\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little function that just run a SQL query without processing the result (do NOT use it for SELECT)\n",
    "import sys, traceback\n",
    "\n",
    "def execute_sql(postgresconn, sql_query):\n",
    "    '''\n",
    "    execute_sql returns 0 if all is OK, -1 else\n",
    "    a little function that just run a SQL query without processing the result (do NOT use it for SELECT)\n",
    "    catch exceptions and print some errors if the SQL was badly formatted\n",
    "    '''\n",
    "    #Get a cursor\n",
    "    cur = postgresconn.cursor()\n",
    "    try:\n",
    "        cur.execute(sql_query)\n",
    "    except Exception as e:\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        print(e)\n",
    "        print(repr(traceback.format_exception(exc_type, exc_value, exc_traceback)))\n",
    "        print(sql_query)\n",
    "        return -1\n",
    "    \n",
    "    cur.close() #Close the cursor\n",
    "    postgresconn.commit() #Commit the data\n",
    "    return 0\n",
    "\n",
    "def select_sql(postgresconn, sql_query):\n",
    "    ''' select_sql returns a list of tuples (rows) corresponding to the answer\n",
    "        a little function that run a SELECT SQL query and send back the result (use it for SELECT)\n",
    "        catch exceptions and print some errors if the SQL was badly formatted\n",
    "        rows = select_sql('SELECT something, anotherthing FROM atable');\n",
    "        for row in rows:\n",
    "            print ('Valeur de something: ', str(row[0]))\n",
    "            print ('Valeur de anotherthing: ', str(row[1]))\n",
    "    '''\n",
    "    cur = postgresconn.cursor()  #Get a cursor\n",
    "    result = None\n",
    "    try:\n",
    "        cur.execute(sql_query)\n",
    "        result= cur.fetchall()\n",
    "    except Exception as e:\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        print(e)\n",
    "        print(repr(traceback.format_exception(exc_type, exc_value, exc_traceback)))\n",
    "        print(sql_query)\n",
    "\n",
    "    cur.close() #Close the cursor\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let do the job\n",
    "\n",
    "# Define the SQL queries\n",
    "sql_query = \"\"\"alter table kap_hoegh_gls drop column \"index\";\n",
    "alter table kap_hoegh_gls rename column \"ID\" to ID;\n",
    "alter table kap_hoegh_gls alter column dategps type date USING dategps::date;\n",
    "alter table kap_hoegh_gls alter column timegps type time USING timegps::time;\n",
    "alter table kap_hoegh_gls add column timestampgps timestamp ;\n",
    "update kap_hoegh_gls set timestampgps =  (dategps ||' '|| timegps)::timestamp;\"\"\"\n",
    "\n",
    "conn = getConnection()\n",
    "ok = execute_sql(conn, sql_query)\n",
    "conn.close() #Close the connection\n",
    "\n",
    "''' The same as : \n",
    "cur = conn.cursor()\n",
    "cur.execute(sql_query)\n",
    "cur.close() #Close the cursor\n",
    "conn.commit() #Commit the data\n",
    "'''\n",
    "\n",
    "print(ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add the geographic dimension\n",
    "\n",
    "```SQL\n",
    "alter table kap_hoegh_gls add column  pointgps geometry;\n",
    "update kap_hoegh_gls set pointgps =  st_makepoint(long, lat_compensate);\n",
    "-- Indiquer la projection\n",
    "update kap_hoegh_gls set pointgps = st_setsrid(pointgps, 4326) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SQL queries\n",
    "sql_query = \"\"\"alter table kap_hoegh_gls add column  pointgps geometry;\n",
    "update kap_hoegh_gls set pointgps =  st_makepoint(long, lat_compensate);\n",
    "-- Indiquer la projection\n",
    "update kap_hoegh_gls set pointgps = st_setsrid(pointgps, 4326) \n",
    "\"\"\"\n",
    "\n",
    "conn = getConnection()\n",
    "ok = execute_sql(conn, sql_query)\n",
    "conn.close() #Close the connection\n",
    "print(ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a bird path\n",
    "Make a GROUP BY bird_id, and sort in chronological order each point per bird \n",
    "\n",
    "```SQL\n",
    "-- let's compute the path\n",
    "select id, st_makeline(pointgps)\n",
    "from (\n",
    "\tselect id, pointgps, timestampgps from kap_hoegh_gls order by id, timestampgps\n",
    ") as q \n",
    "group by id\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_query = \"\"\"select id, st_makeline(pointgps)\n",
    "from (\n",
    "\tselect id, pointgps, timestampgps from kap_hoegh_gls order by id, timestampgps\n",
    ") as q \n",
    "group by id\"\"\"\n",
    "conn = getConnection()\n",
    "ok = execute_sql(conn, sql_query)\n",
    "conn.close() #Close the connection\n",
    "print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You would like to save it ?\n",
    "sql_query = \"\"\"create table bird_paths as (\n",
    "\tselect id, st_makeline(pointgps) as linepath\n",
    "\tfrom (select id, pointgps, timestampgps from kap_hoegh_gls order by id, timestampgps) as q \n",
    "\tgroup by id\n",
    "\t)\"\"\"\n",
    "conn = getConnection()\n",
    "ok = execute_sql(conn, sql_query)\n",
    "conn.close() #Close the connection\n",
    "print(ok)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the total length of the path\n",
    "\n",
    "```SQL \n",
    "alter table bird_paths add column migration_length float;\n",
    "update bird_paths set migration_length = round(st_length(linepath, true)/ 1000);\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"alter table bird_paths add column migration_length float;\n",
    "update bird_paths set migration_length = round(st_length(linepath, true)/ 1000);\"\"\"\n",
    "\n",
    "conn = getConnection()\n",
    "ok = execute_sql(conn, sql_query)\n",
    "conn.close() #Close the connection\n",
    "print(ok)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a bokeh map and/or a folium map (you can use geopandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First with bokeh\n",
    "\n",
    "https://docs.bokeh.org/en/latest/docs/user_guide/topics/geo.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with Bokeh\n",
    "\n",
    "## Most simple of the tutorial\n",
    "from bokeh.plotting import figure, show\n",
    "import xyzservices.providers as xyz\n",
    "\n",
    "# range bounds supplied in web mercator coordinates\n",
    "p = figure(x_range=(-2000000, 2000000), y_range=(1000000, 7000000),\n",
    "           x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "\n",
    "p.add_tile(xyz.OpenStreetMap.Mapnik)\n",
    "#p.add_tile(\"CartoDB Positron\", retina=True)\n",
    "\n",
    "show(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from bokeh.models import GeoJSONDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.sampledata.sample_geojson import geojson\n",
    "\n",
    "data = json.loads(geojson)\n",
    "\n",
    "print(geojson)\n",
    "\n",
    "for i in range(len(data['features'])):\n",
    "    data['features'][i]['properties']['Color'] = ['blue', 'red'][i%2]\n",
    "\n",
    "print(json.dumps(data))\n",
    "\n",
    "geo_source = GeoJSONDataSource(geojson=json.dumps(data))\n",
    "\n",
    "TOOLTIPS = [('pinpin', '@OrganisationName')]\n",
    "\n",
    "p = figure(background_fill_color=\"lightgrey\", tooltips=TOOLTIPS)\n",
    "\n",
    "p.circle(x='x', y='y', size=15, color='Color', alpha=0.7, source=geo_source)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to get a geojson (if you read the tutorial). \n",
    "I show you how to get it from the database. \n",
    "\n",
    "You remember that ?\n",
    "```SQL\n",
    "SELECT jsonb_build_object(\n",
    "    'type', 'FeatureCollection',\n",
    "    'features', jsonb_agg(feature)\n",
    ")\n",
    "FROM (\n",
    "    SELECT jsonb_build_object(\n",
    "    'type', 'Feature',\n",
    "    'id', ogc_fid,\n",
    "    'geometry', ST_AsGeoJSON(geom4326, 2)::jsonb,\n",
    "    'properties', to_jsonb(row) - 'geom4326' - 'ogc_fid'\n",
    "    ) AS feature\n",
    "    FROM (\n",
    "        SELECT ogc_fid, uhgs_id, toponyme_standard_fr, toponyme_standard_en, state_1789_fr, state_1789_en, \n",
    "        admiralty as amiraute, province, status, \n",
    "        round(st_x(geom)::numeric, 2) AS long, \n",
    "        round(st_y(geom)::numeric, 2) AS lat, \n",
    "        geom as geom4326 \n",
    "        FROM public.port_points pp \n",
    ") row) features; \n",
    "```\n",
    "\n",
    "Let's adapt it\n",
    "```SQL\n",
    "SELECT jsonb_build_object(\n",
    "    'type', 'FeatureCollection',\n",
    "    'features', jsonb_agg(feature)\n",
    ")\n",
    "FROM (\n",
    "    SELECT jsonb_build_object(\n",
    "    'type', 'Feature',\n",
    "    'id', id,\n",
    "    'geometry', ST_AsGeoJSON(linepath, 3)::jsonb,\n",
    "    'properties', to_jsonb(row) - 'linepath' - 'id'\n",
    "    ) AS feature\n",
    "    FROM (\n",
    "        SELECT id, migration_length, linepath from bird_paths \n",
    ") row) features; \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from bokeh.models import GeoJSONDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "## Query you database to get the list \n",
    "sql_query = \"\"\"SELECT jsonb_build_object(\n",
    "    'type', 'FeatureCollection',\n",
    "    'features', jsonb_agg(feature)\n",
    ")\n",
    "FROM (\n",
    "    SELECT jsonb_build_object(\n",
    "    'type', 'Feature',\n",
    "    'id', id,\n",
    "    'geometry', ST_AsGeoJSON(linepath, 3)::jsonb,\n",
    "    'properties', to_jsonb(row) - 'linepath' \n",
    "    ) AS feature\n",
    "    FROM (\n",
    "        SELECT id, migration_length, st_transform(linepath, 3857) as linepath from bird_paths \n",
    ") row) features; \"\"\"\n",
    "conn = getConnection()\n",
    "rows = select_sql(conn, sql_query)\n",
    "conn.close() #Close the connection\n",
    "\n",
    "\n",
    "\n",
    "data = json.loads(json.dumps(rows[0][0]))\n",
    "print (len(data['features'])) #Number of bird paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plot\n",
    "\n",
    "from bokeh.palettes import GnBu, PiYG11,Set3, Category20, Category20c\n",
    "\n",
    "#from bokeh.sampledata.sample_geojson import geojson\n",
    "#data2 = json.loads(geojson)\n",
    "\n",
    "#point_mapper2 = factor_cmap(field_name='timeasfactor', palette=Category20c[len(data['features'])], factors=np.unique(np.sort(pd.to_datetime(thisbirdtimes).month)).astype(str))\n",
    "\n",
    "palette=Category20c[len(data['features'])]\n",
    "                \n",
    "for i in range(len(data['features'])):\n",
    "    #data['features'][i]['properties']['Color'] = ['blue', 'red'][i%2]\n",
    "    data['features'][i]['properties']['Color'] = palette[i]\n",
    "    #print(len(data['features'][i]['geometry']['coordinates'][0] ))\n",
    "    #print(data['features'][i]['id'])\n",
    "    #print(data['features'][i]['properties']['Color'])\n",
    "    #print(data['features'][i]['properties']['migration_length'])\n",
    "geo_source = GeoJSONDataSource(geojson=json.dumps(data))\n",
    "\n",
    "print(geo_source.geojson)\n",
    "\n",
    "# Bokeh converts the GeoJSON coordinates into columns called x and y or xs and ys (depending on whether the features are Points, Lines, MultiLines, Polygons, or MultiPolygons). \n",
    "# Properties with clashing names will be overridden when the GeoJSON is converted and should be avoided.\n",
    "TOOLTIPS = [('migration length', '@migration_length'), ('bird id', '@id')]\n",
    "\n",
    "p = figure(x_range=(-9587947, 1113194), y_range=(3503549, 13195489),\n",
    "           x_axis_type=\"mercator\", y_axis_type=\"mercator\", \n",
    "           background_fill_color=\"lightgrey\",  tooltips=TOOLTIPS)\n",
    "\n",
    "p.add_tile(\"CartoDB Positron\", retina=True)\n",
    "\n",
    "p.multi_line(xs='xs', ys='ys', line_color='Color', source=geo_source, line_width=1)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could have use folium \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's up to you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing of cleaned GPS data\n",
    "\n",
    "Inspired by https://fda.readthedocs.io/en/latest/auto_examples/plot_kernel_smoothing.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "n_neighbors = np.arange(2, 24)\n",
    "print(n_neighbors)\n",
    "dist = 1\n",
    "bandwidth = np.linspace(\n",
    "    dist,\n",
    "    dist * (math.ceil((n_neighbors[-1] - 1) / 2)),\n",
    "    len(n_neighbors),\n",
    ")\n",
    "\n",
    "bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First clean roughly the coordinates : have a look on latitudes and longitudes distribution, to remove strange values (outliers)\n",
    "\n",
    "Then, you can save it into clean_lat and clean_long\n",
    "```SQL \n",
    "alter table kap_hoegh_gls add column if not exists clean_lat float null;\n",
    "update kap_hoegh_gls set clean_lat = null;\n",
    "update kap_hoegh_gls set clean_lat = lat where lat < 85 and lat > 35; -- 26974 lines\n",
    "\n",
    "alter table kap_hoegh_gls add column smooth_lat float;\n",
    "alter table kap_hoegh_gls add column clean_long float;\n",
    "alter table kap_hoegh_gls add column smooth_long float;\n",
    "\n",
    "update kap_hoegh_gls set clean_long = null;\n",
    "update kap_hoegh_gls set clean_long = long where long < 75 and long > -75; -- 26974 lines\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df.id==148].timestampgps.values\n",
    "y = df[df.id==148].clean_lat.values\n",
    "x\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsmoothie.smoother import * #pip install tsmoothie\n",
    "import pandas.io.sql as sql\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "query= \"\"\"select id, timestampgps, clean_lat, clean_long \n",
    "    from arctic_christine.kap_hoegh_gls \n",
    "    order by id, timestampgps \"\"\"\n",
    "df = sql.read_sql_query(text(query), engine.connect())\n",
    "\n",
    "#x = df.loc[:, ['timestampgps']].values #timestampgps\n",
    "#y = df.loc[:,['clean_lat']].values\n",
    "x = df[df.id==148].timestampgps.values\n",
    "y = df[df.id==148].clean_lat.values\n",
    "\n",
    "#https://pypi.org/project/tsmoothie/\n",
    "#https://fr.wikipedia.org/wiki/Fen%C3%AAtrage \n",
    "#Second one : moving weighted average of span = 10, using hamming function\n",
    "smoother = ConvolutionSmoother(window_len=20, window_type='hamming')\n",
    "smoother.smooth(y)\n",
    "\n",
    "# generate intervals\n",
    "low, up = smoother.get_intervals('sigma_interval', n_sigma=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
